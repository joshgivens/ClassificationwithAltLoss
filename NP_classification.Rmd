---
title: "NP Classification"
output: html_document
date: "2024-06-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(dplyr)
library(nproc)
library(pROC)
#library(ggpubr)
#library(data.table)
#library(purrr)
#library(MASS)

set.seed(123)
```


```{r}
# load data
df <- read.csv("/home/ia23879/Documents/Computing 1/Variant I.csv") %>% 
  as.data.frame() %>%
  na.omit()
```


```{r}
# remove 'income', 'customer_age', 'employment_status' columns as they are protected
data1 <- df %>% 
  select_at(-c(2, 6, 16)) 


# convert categorical variables in 'payment_type' to integers
data1 <- data1 %>% 
  mutate(payment_type =  as.integer(as.factor(payment_type)),
         housing_status =  as.integer(as.factor(housing_status)),
         source =  as.integer(as.factor(source)),
         device_os =  as.integer(as.factor(device_os)))

# remove the variable which are the same for all samples
rep.col <- c()
for(i in 1:ncol(data1)){
  # if replicate
  if(length(unique(data1[,i]))==1){
    rep.col <- c(rep.col, i)
  }
}

# remove these column
data1 <- data1[,-rep.col]

# Display the first few rows of the modified dataframe
head(data1)

```


# Train-test splitting

```{r}
# split ratio
split.ratio <- 0.7

# row index of label 1
lab1.idx <- which(data1[,1]==1)

# row index of label 0
lab0.idx <- which(data1[,1]==0)

# randomly sampling training data
train.lab1 <- sample(x = lab1.idx,
                     size = round(0.7*length(lab1.idx)), 
                     replace = FALSE)
train.lab0 <- sample(x = lab0.idx,
                     size = round(0.7*length(lab0.idx)), 
                     replace = FALSE)
train.idx <- c(train.lab1, train.lab0)

# construct X and y as training set
X.train <- data1[train.idx,-1]
y.train <-  data1[train.idx,1]

# construct X and y as test set
X.test <- data1[-train.idx,-1]
y.test <-  data1[-train.idx,1]

training_data <- data.frame(y.train, X.train)
test_data <- data.frame(y.test, X.test)
```

# Check data balance in training data

```{r}
# Calculate the number of 0s and 1s in the data
y_counts <- table(data1$fraud_bool)

# Calculate the percentage of 0s and 1s
y_percentages <- prop.table(y_counts) * 100

# Print the counts and percentages
print(y_counts)
print(y_percentages)
```


```{r}
# Calculate the number of 0s and 1s in y.test
y_counts <- table(y.train)

# Calculate the percentage of 0s and 1s
y_percentages <- prop.table(y_counts) * 100

# Print the counts and percentages
print(y_counts)
print(y_percentages)
```


# Try logistic regression first

```{r}
fit = npc(X.train, y.train, method = "logistic")
```

# Check overall accuracy

```{r}
pred = predict(fit, X.test)

accuracy = mean(pred$pred.label == y.test)
cat("Overall Accuracy: ", accuracy,'\n')
```

# Check Type 1 error

```{r}
ind0 = which(y.test == 0)
typeI = mean(pred$pred.label[ind0] != y.test[ind0])
cat('Type I error: ', typeI, '\n')
```


```{r}
fit_nproc = nproc(X.train, y.train, method = "logistic")
plot(fit_nproc)
```


# Try svm on 10% of the data

# Proportional sampling

```{r}
library(caret)
```

# Training data around 100 000 (10%) and test data around 50 000 (5%)

```{r}
# Sample from training data
set.seed(123)
index <- createDataPartition(training_data$y.train, p = 0.143, list = TRUE)
train <- training_data[index$Resample,]
train %>% dplyr::count(y.train)

X.train.sub <- train[,-1]
y.train.sub <-  train[,1]

# Sample from testing data
index <- createDataPartition(test_data$y.test, p = 0.167, list = TRUE)
test<- test_data[index$Resample,]

X.test.sub <- test[,-1]
y.test.sub <-  test[,1]
```


```{r}
dim(X.train.sub)
dim(X.test.sub)
```


```{r}
# Calculate the number of 0s and 1s in the data
y_counts <- table(y.train.sub)

# Calculate the percentage of 0s and 1s
y_percentages <- prop.table(y_counts) * 100

# Print the counts and percentages
print(y_counts)
print(y_percentages)
```

# Fit svm on proportional subsample

```{r}
fit_svm = npc(X.train.sub, y.train.sub, method = "svm")
```

# Check overall accuracy

```{r}
pred_svm = predict(fit_svm, X.test.sub)

accuracy = mean(pred_svm$pred.label == y.test.sub)
cat("Overall Accuracy: ", accuracy,'\n')
```

# Check Type 1 error

```{r}
ind0 = which(y.test.sub == 0)
typeI = mean(pred_svm$pred.label[ind0] != y.test.sub[ind0])
cat('Type I error: ', typeI, '\n')
```

```{r}
fit_nproc_svm = nproc(X.train.sub, y.train.sub, method = "svm")
```

```{r}
plot(fit_nproc_svm)
```


```{r}
v <- compare(fit_nproc, fit_nproc_svm)
legend('topleft',legend = c("logistic", "svm"), col = 1:2,lty = c(1,1))
```


# ROSE sampling

```{r}
library(ROSE)
```


```{r}
data_rose <- ROSE(y.train~., data = training_data, p=0.5)$data
```


```{r}
# Train data
set.seed(123)
index <- createDataPartition(data_rose$y.train, p = 0.143, list = TRUE)
train <- data_rose[index$Resample,]
train %>% dplyr::count(y.train)

X.train.rose <- train[,-1]
y.train.rose <-  train[,1]
```

# Fit svm on ROSE sample

```{r}
fit_rose = npc(X.train.rose, y.train.rose, method = "svm")
```

# Check overall accuracy

```{r}
pred_rose = predict(fit_rose, X.test.sub)

accuracy = mean(pred_rose$pred.label == y.test.sub)
cat("Overall Accuracy: ", accuracy,'\n')
```

# Check Type 1 error

```{r}
ind0 = which(y.test.sub == 0)
typeI = mean(pred_rose$pred.label[ind0] != y.test.sub[ind0])
cat('Type I error: ', typeI, '\n')
```

```{r}
fit_nproc_rose = nproc(X.train.rose, y.train.rose, method = "svm")
```

```{r}
plot(fit_nproc_rose)
```

```{r}
v <- compare(fit_nproc, fit_nproc_rose)
legend('topleft',legend = c("logistic", "rose svm"), col = 1:2,lty = c(1,1))
```

```{r}
v <- compare(fit_nproc_svm, fit_nproc_rose)
legend('topleft',legend = c("svm", "rose svm"), col = 1:2,lty = c(1,1))
```

```{r}
plot(fit_nproc_rose)
lines(fit_nproc_svm, col = 2)
lines(fit_nproc, col = 3)
legend('topleft',legend = c("rose svm", "svm", "logistic"), col = 1:3,lty = c(1,1))
```


# SMOTE sampling

```{r}
library(performanceEstimation)
```

```{r}
data_smote <- smote(y.train~., data = training_data %>% mutate(y.train = as.factor(y.train)), perc.over = 6, perc.under = 1.1)
```


```{r}
# Calculate the number of 0s and 1s in the data
y_counts <- table(y.train.smote)

# Calculate the percentage of 0s and 1s
y_percentages <- prop.table(y_counts) * 100

# Print the counts and percentages
print(y_counts)
print(y_percentages)
```

# Fit svm on SMOTE sample

```{r}
fit_smote = npc(X.train.smote, y.train.smote, method = "svm")
```

# Check overall accuracy

```{r}
pred_smote = predict(fit_smote, X.test.sub)

accuracy = mean(pred_smote$pred.label == y.test.sub)
cat("Overall Accuracy: ", accuracy,'\n')
```

# Check Type 1 error

```{r}
ind0 = which(y.test.sub == 0)
typeI = mean(pred_smote$pred.label[ind0] != y.test.sub[ind0])
cat('Type I error: ', typeI, '\n')

```

```{r}
fit_nproc_smote = nproc(X.train.smote, y.train.smote, method = "svm")
```

```{r}
plot(fit_nproc_smote)
```

```{r}
v <- compare(fit_nproc, fit_nproc_smote)
legend('topleft',legend = c("logistic", "svm smote"), col = 1:2,lty = c(1,1))
```


```{r}
v <- compare(fit_nproc_rose, fit_nproc_smote)
legend('topleft',legend = c("rose svm", " smote svm"), col = 1:2,lty = c(1,1))
```

```{r}
plot(fit_nproc_rose)
lines(fit_nproc_svm, col = 2)
lines(fit_nproc, col = 3)
lines(fit_nproc_smote, col = 4)
legend('topleft',legend = c("rose svm", "svm", "logistic", "smote svm"), col = 1:4,lty = c(1,1))
```

# Random Forest approach 

# Fit randomforest on proportional subsample

```{r}
fit_rf = npc(X.train.sub, y.train.sub, method = "randomforest")
```

# Check overall accuracy

```{r}
pred_rf = predict(fit_rf, X.test.sub)

accuracy = mean(pred_rf$pred.label == y.test.sub)
cat("Overall Accuracy: ", accuracy,'\n')
```

# Check Type 1 error

```{r}
ind0 = which(y.test.sub == 0)
typeI = mean(pred_rf$pred.label[ind0] != y.test.sub[ind0])
cat('Type I error: ', typeI, '\n')
```


```{r}
fit_nproc_rf = nproc(X.train.sub, y.train.sub, method = "randomforest")
```


```{r}
plot(fit_nproc_rf)
```


```{r}
v <- compare(fit_nproc, fit_nproc_rf)
legend('topleft',legend = c("logistic", "random forest"), col = 1:2,lty = c(1,1))
```

# ROSE sample random forest

```{r}
fit_rose_tree = npc(X.train.rose, y.train.rose, method = "randomforest")
```

# Check overall accuracy

```{r}
pred_rose_tree = predict(fit_rose_tree, X.test.sub)

accuracy = mean(pred_rose_tree$pred.label == y.test.sub)
cat("Overall Accuracy: ", accuracy,'\n')
```

# Check Type 1 error

```{r}
ind0 = which(y.test.sub == 0)
typeI = mean(pred_rose_tree$pred.label[ind0] != y.test.sub[ind0])
cat('Type I error: ', typeI, '\n')
```

```{r}
nproc_rose_tree = nproc(X.train.rose, y.train.rose, method = "randomforest")
```


```{r}
plot(nproc_rose_tree)
```


```{r}
plot(fit_nproc_rose)
lines(fit_nproc_svm, col = 2)
lines(fit_nproc, col = 3)
lines(fit_nproc_smote, col = 4)
lines(fit_nproc_rf, col = 5)
lines(nproc_rose_tree, col = 6)
legend('bottomright',legend = c("rose svm", "svm", "logistic", "smote svm", "rf", "rose rf"), col = 1:6,lty = c(1,1))
```

```{r}
v <- compare(nproc_rose_tree, fit_nproc_rf)
legend('topleft',legend = c("rose rf", "rf"), col = 1:2,lty = c(1,1))
```


```{r}
v <- compare(nproc_rose_tree, fit_nproc_smote)
legend('topleft',legend = c("rose rf", "smote svm"), col = 1:2,lty = c(1,1))
```

# SMOTE random forest

```{r}
fit_smote_rf = npc(X.train.smote, y.train.smote, method = "randomforest")
```

# Check overall accuracy

```{r}
pred_smote_rf = predict(fit_smote_rf, X.test.sub)

accuracy = mean(pred_smote_rf$pred.label == y.test.sub)
cat("Overall Accuracy: ", accuracy,'\n')
```

# Check Type 1 error

```{r}
ind0 = which(y.test.sub == 0)
typeI = mean(pred_smote_rf$pred.label[ind0] != y.test.sub[ind0])
cat('Type I error: ', typeI, '\n')
```

```{r}
fit_nproc_smote_rf = nproc(X.train.smote, y.train.smote, method = "randomforest")
```

```{r}
plot(fit_nproc, col = 1)
lines(fit_nproc_svm, col = 2)
lines(fit_nproc_rose, col = 3)
lines(fit_nproc_smote, col = 4)
lines(fit_nproc_rf, col = 5)
lines(nproc_rose_tree, col = 6)
lines(fit_nproc_smote_rf, col =7)
legend('bottomright',legend = c("logistic", "svm", "rose svm", "smote svm", "rf", "rose rf", "smote rf"), col = 1:7,lty = c(1,1))
```

```{r}
fit_nproc_smote_rf$auc.l
fit_nproc_smote_rf$auc.u
```

